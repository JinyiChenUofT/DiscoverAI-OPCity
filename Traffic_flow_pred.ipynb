{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Traffic_flow_pred.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH52Een9qpo_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10SyrFEHxkMK",
        "colab_type": "text"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3lD-HC2q8Tm",
        "colab_type": "code",
        "outputId": "cbd3c762-b2f9-42d5-f7ca-955769800f25",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 77
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-eb9b56c3-d524-48d7-a35c-07a79f794b80\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-eb9b56c3-d524-48d7-a35c-07a79f794b80\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving VDS_Gardiner VDS_NO.89_log.csv to VDS_Gardiner VDS_NO.89_log.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpNXAJG_au0Z",
        "colab_type": "text"
      },
      "source": [
        "# 新段落"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr_MPk0TzKNw",
        "colab_type": "text"
      },
      "source": [
        "The Columns in Detail:\n",
        "\n",
        "1st Column: Date/ time of the feed (Time Stamp)\n",
        "\n",
        "2nd Column: Unique continuous ID for each detector base on the road direction (easy for subscription)\n",
        "\n",
        "3rd Column: Detector Name in the system\n",
        "\n",
        "4th Column: Detector physical address\n",
        "\n",
        "5th Column: Detector's Latitude\n",
        "\n",
        "6th Column: Detector's Longitude\n",
        "\n",
        "7th Column: Integer represnting the lane at which vehicles are being detected (Lane Index)\n",
        "\n",
        "8th Column: % of time loop is occupied per interval\n",
        "\n",
        "9th Column: Average speed during an interval (km/h)\n",
        "\n",
        "10th Column: vehicles per interval in (100 vehicle/hour)\n",
        "\n",
        "11th Column: VdsDevice's unique ID\n",
        "\n",
        "12th Colunn: Region Name where the detector is located"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZnEiFocwpXv",
        "colab_type": "code",
        "outputId": "f8c3dc86-9280-47cb-d7be-7d63c7cac6c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "data = pd.read_csv(\"VDS_Gardiner VDS_NO.89_log.csv\")\n",
        "data = data[data['onerHourBefore100VehiclesPerHour'].notna()]\n",
        "data.index = pd.to_datetime(data['timeStamp'])\n",
        "data['Hour'] = data.index.hour\n",
        "data['Minute'] = data.index.minute\n",
        "del data['timeStamp']\n",
        "del data['detectorID']\n",
        "data = data.reset_index(drop = True)\n",
        "data.loc[data.dayOfWeek == 'Mon','dayOfWeek'] = 1\n",
        "data.loc[data.dayOfWeek == 'Tue','dayOfWeek'] = 2\n",
        "data.loc[data.dayOfWeek == 'Wed','dayOfWeek'] = 3\n",
        "data.loc[data.dayOfWeek == 'Thu','dayOfWeek'] = 4\n",
        "data.loc[data.dayOfWeek == 'Fri','dayOfWeek'] = 5\n",
        "data.loc[data.dayOfWeek == 'Sat','dayOfWeek'] = 6\n",
        "data.loc[data.dayOfWeek == 'Sun','dayOfWeek'] = 7\n",
        "data[0:10]"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>averageSpeed</th>\n",
              "      <th>100VehiclesPerHour</th>\n",
              "      <th>dayOfWeek</th>\n",
              "      <th>onerHourBefore100VehiclesPerHour</th>\n",
              "      <th>Hour</th>\n",
              "      <th>Minute</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>106</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>76</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>62</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   averageSpeed  100VehiclesPerHour  ...  Hour  Minute\n",
              "0             0                   0  ...     1       0\n",
              "1             0                   0  ...     1       2\n",
              "2            67                   1  ...     1       4\n",
              "3           106                   1  ...     1       6\n",
              "4             0                   0  ...     1       8\n",
              "5            76                   1  ...     1      10\n",
              "6            62                   1  ...     1      12\n",
              "7             0                   0  ...     1      14\n",
              "8             0                   0  ...     1      16\n",
              "9             0                   0  ...     1      18\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pNXZ7DVbVfx",
        "colab_type": "text"
      },
      "source": [
        "#DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FqUagpynwz-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "catcols = [\"averageSpeed\",\t\"100VehiclesPerHour\",\t\"dayOfWeek\",\t\"onerHourBefore100VehiclesPerHour\",\t\"Hour\",\t\"Minute\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWDr3CP3bUxr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "665873ae-96cc-42ed-93d4-73eb9e280402"
      },
      "source": [
        "np.random.seed(50) # set the numpy seed for consistent split\n",
        "arr = np.arange(len(data))\n",
        "np.random.shuffle(arr)\n",
        "np_data=data.values\n",
        "shuffled_data=np.array([np_data[x,:] for x in arr])\n",
        "total_data=len(shuffled_data)\n",
        "train_data=shuffled_data[:int(total_data*0.7)].astype(np.float32)\n",
        "validation_data=shuffled_data[int(total_data*0.7):int(total_data*0.85)].astype(np.float32)\n",
        "test_data=shuffled_data[int(total_data*0.85):].astype(np.float32)\n",
        "print(\"Training dataset size: {}\".format(train_data.shape[0]))\n",
        "print(\"Validation dataset size: {}\".format(validation_data.shape[0]))\n",
        "print(\"Test dataset size: {}\".format(test_data.shape[0]))"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training dataset size: 4200\n",
            "Validation dataset size: 900\n",
            "Test dataset size: 900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZV9VclvxBkk",
        "colab_type": "text"
      },
      "source": [
        "#Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA5R6RKGxBCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TnxuIqfxa_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cuda = torch.device('cuda')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAN0lAyGyH0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model_name(name, batch_size, learning_rate, epoch, momentum):\n",
        "  \"\"\" Generate a name for the model consisting of all the hyperparameter values\n",
        "  Args:\n",
        "  config: Configuration object containing the hyperparameters\n",
        "  Returns:\n",
        "  path: A string with the hyperparameter name and value concatenated\n",
        "  \"\"\"\n",
        "  if momentum:\n",
        "    path = \"model_{0}_bs{1}_lr{2}_epoch{3}_momentum{4}\".format(name,\n",
        "            batch_size,\n",
        "            learning_rate,\n",
        "            epoch,momentum)\n",
        "  else:\n",
        "    path = \"model_{0}_bs{1}_lr{2}_epoch{3}\".format(name,\n",
        "            batch_size,\n",
        "            learning_rate,\n",
        "            epoch)\n",
        "  return path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMwy_yq5xdhP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AutoEncoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(AutoEncoder, self).__init__()\n",
        "    self.encoder = nn.Sequential(\n",
        "    nn.Linear(6, 18), # TODO\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(18, 32),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(32, 64),\n",
        "    nn.ReLU(),\n",
        "    )\n",
        "    self.decoder = nn.Sequential(\n",
        "    nn.Linear(64, 32),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(32, 6),# TODO\n",
        "    nn.Sigmoid() # get to the range (0, 1)\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    x = self.encoder(x)\n",
        "    x = self.decoder(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIIqpbmioI58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat_index = {}  # Mapping of feature -> start index of feature in a record\n",
        "cat_values = {} # Mapping of feature -> list of categorical values the feature can take\n",
        "\n",
        "# build up the cat_index and cat_values dictionary\n",
        "for i, header in enumerate(data.keys()):\n",
        "    if \"_\" in header: # categorical header\n",
        "        feature, value = header.split()\n",
        "        feature = feature[:-1] # remove the last char; it is always an underscore\n",
        "        if feature not in cat_index:\n",
        "            cat_index[feature] = i\n",
        "            cat_values[feature] = [value]\n",
        "        else:\n",
        "            cat_values[feature].append(value)\n",
        "def get_onehot(record, feature):\n",
        "    \"\"\"\n",
        "    Return the portion of `record` that is the one-hot encoding\n",
        "    of feature. For example, since the feature \"work\" is stored\n",
        "    in the indices [5:12] in each record, calling `get_range(record, \"work\")`\n",
        "    is equivalent to accessing `record[5:12]`.\n",
        "    \n",
        "    Args:\n",
        "        - record: a numpy array representing one record, formatted\n",
        "                  the same way as a row in `data.np`\n",
        "        - feature: a string, should be an element of `catcols`\n",
        "    \"\"\"\n",
        "    start_index = cat_index[feature]\n",
        "    stop_index = cat_index[feature] + len(cat_values[feature])\n",
        "    return record[start_index:stop_index]\n",
        "\n",
        "def get_categorical_value(onehot, feature):\n",
        "    \"\"\"\n",
        "    Return the categorical value name of a feature given\n",
        "    a one-hot vector representing the feature.\n",
        "    \n",
        "    Args:\n",
        "        - onehot: a numpy array one-hot representation of the feature\n",
        "        - feature: a string, should be an element of `catcols`\n",
        "        \n",
        "    Examples:\n",
        "    \n",
        "    >>> get_categorical_value(np.array([0., 0., 0., 0., 0., 1., 0.]), \"work\")\n",
        "    'State-gov'\n",
        "    >>> get_categorical_value(np.array([0.1, 0., 1.1, 0.2, 0., 1., 0.]), \"work\")\n",
        "    'Private'\n",
        "    \"\"\"\n",
        "    # TODO\n",
        "    idx = np.argmax(onehot)\n",
        "    return cat_values[feature][idx]\n",
        "def get_feature(record, feature):\n",
        "    \"\"\"\n",
        "    Return the categorical feature value of a record\n",
        "    \"\"\"\n",
        "    onehot = get_onehot(record, feature)\n",
        "    return get_categorical_value(onehot, feature)\n",
        "\n",
        "def get_features(record):\n",
        "    \"\"\"\n",
        "    Return a dictionary of all categorical feature values of a record\n",
        "    \"\"\"\n",
        "    return { f: get_feature(record, f) for f in catcols }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HrXn4gcqHPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_accuracy(model, data_loader):\n",
        "    \"\"\"Return the \"accuracy\" of the autoencoder model across a data set\n",
        "    \n",
        "    Args:\n",
        "       - model: the autoencoder model, an instance of nn.Module\n",
        "       - data_loader: an instance of torch.utils.data.DataLoader\n",
        "\n",
        "    Example (to illustrate how get_accuracy is intended to be called.\n",
        "             depending on your variable naming this code might not work\n",
        "             out of the box)\n",
        "\n",
        "        >>> model = AutoEncoder()\n",
        "        >>> vdl = torch.utils.data.DataLoader(data_valid, batch_size=256, shuffle=True)\n",
        "        >>> get_accuracy(model, vdl)\n",
        "    \"\"\"\n",
        "    total = 0\n",
        "    acc = 0\n",
        "    for col in catcols:\n",
        "        for item in data_loader: # minibatches\n",
        "            inp = item.detach().numpy()\n",
        "            out = model(zero_out_feature(item.clone())).detach().numpy()\n",
        "            for i in range(out.shape[0]): # record in minibatch\n",
        "                acc += np.square(out[i][1] - inp[i][1] )\n",
        "    return acc "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H8yQsG38pX2n",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_training_curve(path):\n",
        "    train_err = np.loadtxt(\"{}_train_acc.csv\".format(path))\n",
        "    val_err = np.loadtxt(\"{}_val_acc.csv\".format(path))\n",
        "    train_loss = np.loadtxt(\"{}_train_loss.csv\".format(path))\n",
        "    val_loss = np.loadtxt(\"{}_val_loss.csv\".format(path))\n",
        "    plt.title(\"Train vs Validation Accuracy\")\n",
        "    plt.plot(range(1,train_err.shape[0]+1), train_err, label=\"Train\")\n",
        "    plt.plot(range(1,val_err.shape[0]+1), val_err, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "    plt.title(\"Train vs Validation Loss\")\n",
        "    plt.plot(range(1,train_loss.shape[0]+1), train_loss, label=\"Train\")\n",
        "    plt.plot(range(1,val_loss.shape[0]+1), val_loss, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "def zero_out_feature(records):\n",
        "    \"\"\" Set the feature missing in records, by setting the appropriate\n",
        "    columns of records to 0\n",
        "    \"\"\"\n",
        "    records[:, 1] = 0\n",
        "    return records\n",
        "\n",
        "def zero_out_random_feature(records):\n",
        "    \"\"\" Set one random feature missing in records, by setting the \n",
        "    appropriate columns of records to 0\n",
        "    \"\"\"\n",
        "    return zero_out_feature(records)\n",
        "def validation_eval(model, valid_loader, criterion):\n",
        "    valid_error = 0\n",
        "    total_valid_loss = 0\n",
        "    for data_val in valid_loader:\n",
        "        recon=model(data_val)\n",
        "        loss = criterion(recon, data_val)\n",
        "        total_valid_loss += loss.item()\n",
        "    return total_valid_loss/len(valid_loader),get_accuracy(model, valid_loader)\n",
        "        \n",
        "def train(model, train_loader, valid_loader, num_epochs=5, learning_rate=1e-4, batch_size=1,betas=(0.9, 0.999)):\n",
        "    \"\"\" Training loop. You should update this.\"\"\"\n",
        "    torch.manual_seed(42)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,betas=betas)\n",
        "    train_err = []    \n",
        "    train_loss = []  \n",
        "    val_err = []  \n",
        "    val_loss = []\n",
        "    for epoch in range(num_epochs):\n",
        "        train_error = 0\n",
        "        total_train_loss = 0\n",
        "        train_idx = 0\n",
        "        for data in train_loader:\n",
        "            data_zero = zero_out_feature(data.clone()) # zero out one categorical feature\n",
        "            recon = model(data_zero)\n",
        "            loss = criterion(recon, data)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            total_train_loss += loss.item()\n",
        "            if train_idx%1000==0:\n",
        "                train_err.append(get_accuracy(model,  train_loader))\n",
        "                train_loss.append(total_train_loss/(train_idx+1))\n",
        "                valid_loss,valid_err = validation_eval(model, valid_loader,criterion)\n",
        "                val_loss.append(valid_loss)\n",
        "                val_err.append(valid_err)\n",
        "            train_idx+=1\n",
        "        train_loss.append(total_train_loss/len(train_loader))\n",
        "        valid_loss,_= validation_eval(model, valid_loader,criterion)\n",
        "        val_loss.append(valid_loss)\n",
        "        print((\"Epoch {}: Train loss: {} |\"+               \n",
        "               \"Validation loss: {}\").format(\n",
        "            epoch + 1, train_loss[-1],val_loss[-1]))\n",
        "        model_path = \"Encoder_Decoder_Batchsize{}_lr{}_epoch{}_betas{}\".format(batch_size,learning_rate,epoch,betas)\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "    print('Finished Training')    \n",
        "    np.savetxt(\"{}_train_loss.csv\".format(model_path), np.array(train_loss))       \n",
        "    np.savetxt(\"{}_val_loss.csv\".format(model_path), np.array(val_loss))\n",
        "    return model_path\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aby3mMinRRI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "091dd565-b334-425c-879f-353e2ec7fd91"
      },
      "source": [
        "Encoder=AutoEncoder()\n",
        "batch_size=32\n",
        "train_loader =torch.utils.data.DataLoader(train_data,batch_size=batch_size) \n",
        "valid_loader =torch.utils.data.DataLoader(validation_data,batch_size=batch_size) \n",
        "test_loader =torch.utils.data.DataLoader(test_data,batch_size=batch_size) \n",
        "path = train(Encoder, train_loader, valid_loader, num_epochs=30, learning_rate=1e-2, batch_size=batch_size)"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1: Train loss: 943.3446169766513 |Validation loss: 965.1892237169989\n",
            "Epoch 2: Train loss: 942.7918881503018 |Validation loss: 965.1797801050647\n",
            "Epoch 3: Train loss: 942.7917836507162 |Validation loss: 965.1797801050647\n",
            "Epoch 4: Train loss: 942.7917836507162 |Validation loss: 965.1797801050647\n",
            "Epoch 5: Train loss: 942.7917836507162 |Validation loss: 965.1797801050647\n",
            "Epoch 6: Train loss: 942.7917841131037 |Validation loss: 965.1797801050647\n",
            "Epoch 7: Train loss: 942.7917841131037 |Validation loss: 965.1797801050647\n",
            "Epoch 8: Train loss: 942.7917841131037 |Validation loss: 965.1797801050647\n",
            "Epoch 9: Train loss: 942.7917836507162 |Validation loss: 965.1797801050647\n",
            "Epoch 10: Train loss: 942.7917836507162 |Validation loss: 965.1797801050647\n",
            "Epoch 11: Train loss: 942.7917831883286 |Validation loss: 965.1797801050647\n",
            "Epoch 12: Train loss: 942.7917831883286 |Validation loss: 965.1797801050647\n",
            "Epoch 13: Train loss: 942.7917831883286 |Validation loss: 965.1797801050647\n",
            "Epoch 14: Train loss: 942.7917836507162 |Validation loss: 965.1797801050647\n",
            "Epoch 15: Train loss: 942.7917836507162 |Validation loss: 965.1797801050647\n",
            "Epoch 16: Train loss: 942.7917827259411 |Validation loss: 965.1797801050647\n",
            "Epoch 17: Train loss: 942.7917836507162 |Validation loss: 965.1797801050647\n",
            "Epoch 18: Train loss: 942.7917822635535 |Validation loss: 965.1797801050647\n",
            "Epoch 19: Train loss: 942.7917831883286 |Validation loss: 965.1797801050647\n",
            "Epoch 20: Train loss: 942.7917827259411 |Validation loss: 965.1797780004041\n",
            "Epoch 21: Train loss: 942.7917845754912 |Validation loss: 965.1797801050647\n",
            "Epoch 22: Train loss: 942.7917827259411 |Validation loss: 965.1797801050647\n",
            "Epoch 23: Train loss: 942.7917813387784 |Validation loss: 965.1797716864224\n",
            "Epoch 24: Train loss: 942.8388292717211 |Validation loss: 965.2246725148168\n",
            "Epoch 25: Train loss: 942.8415004845822 |Validation loss: 965.2246725148168\n",
            "Epoch 26: Train loss: 942.8415004845822 |Validation loss: 965.2246725148168\n",
            "Epoch 27: Train loss: 942.8415004845822 |Validation loss: 965.2246725148168\n",
            "Epoch 28: Train loss: 942.8415004845822 |Validation loss: 965.2246725148168\n",
            "Epoch 29: Train loss: 942.8415004845822 |Validation loss: 965.2246725148168\n",
            "Epoch 30: Train loss: 942.8415004845822 |Validation loss: 965.2246725148168\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEGSt8lxoNLH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fb8d4f69-56ba-4116-d92a-8233a13d2aba"
      },
      "source": [
        "cat_index"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q28643PnnY3Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}