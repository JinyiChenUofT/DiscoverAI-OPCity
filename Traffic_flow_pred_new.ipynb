{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Traffic_flow_pred.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH52Een9qpo_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10SyrFEHxkMK",
        "colab_type": "text"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIjBkFpyC70q",
        "colab_type": "code",
        "outputId": "99abb83b-8cda-4bf7-bfdc-fcebcd0f0237",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EobU7f18D1tq",
        "colab_type": "code",
        "outputId": "948f4bb7-2aef-4dd1-9e94-edcd98a424c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!unzip /content/drive/My\\ Drive/dot_traffic_2015.txt.gz.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/dot_traffic_2015.txt.gz.zip\n",
            "  inflating: dot_traffic_2015.txt.gz  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLzwJullDCkL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "traffic_df = pd.read_csv('/content/dot_traffic_2015.txt.gz', compression='gzip', header=0, sep=',', quotechar='\"')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_xttvPXStqh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del traffic_df['functional_classification_name']\n",
        "del traffic_df['date']\n",
        "del traffic_df['restrictions']\n",
        "del traffic_df['year_of_data']\n",
        "del traffic_df['record_type']\n",
        "del traffic_df['direction_of_travel_name']\n",
        "del traffic_df['fips_state_code']\n",
        "del traffic_df['station_id']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHFGFZ4kEkAG",
        "colab_type": "code",
        "outputId": "1c0788b8-a1f6-4f35-91df-08f20a5c2b0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "traffic_df.head(10)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>day_of_data</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>direction_of_travel</th>\n",
              "      <th>functional_classification</th>\n",
              "      <th>lane_of_travel</th>\n",
              "      <th>month_of_data</th>\n",
              "      <th>traffic_volume_counted_after_0000_to_0100</th>\n",
              "      <th>traffic_volume_counted_after_0100_to_0200</th>\n",
              "      <th>traffic_volume_counted_after_0200_to_0300</th>\n",
              "      <th>traffic_volume_counted_after_0300_to_0400</th>\n",
              "      <th>traffic_volume_counted_after_0400_to_0500</th>\n",
              "      <th>traffic_volume_counted_after_0500_to_0600</th>\n",
              "      <th>traffic_volume_counted_after_0600_to_0700</th>\n",
              "      <th>traffic_volume_counted_after_0700_to_0800</th>\n",
              "      <th>traffic_volume_counted_after_0800_to_0900</th>\n",
              "      <th>traffic_volume_counted_after_0900_to_1000</th>\n",
              "      <th>traffic_volume_counted_after_1000_to_1100</th>\n",
              "      <th>traffic_volume_counted_after_1100_to_1200</th>\n",
              "      <th>traffic_volume_counted_after_1200_to_1300</th>\n",
              "      <th>traffic_volume_counted_after_1300_to_1400</th>\n",
              "      <th>traffic_volume_counted_after_1400_to_1500</th>\n",
              "      <th>traffic_volume_counted_after_1500_to_1600</th>\n",
              "      <th>traffic_volume_counted_after_1600_to_1700</th>\n",
              "      <th>traffic_volume_counted_after_1700_to_1800</th>\n",
              "      <th>traffic_volume_counted_after_1800_to_1900</th>\n",
              "      <th>traffic_volume_counted_after_1900_to_2000</th>\n",
              "      <th>traffic_volume_counted_after_2000_to_2100</th>\n",
              "      <th>traffic_volume_counted_after_2100_to_2200</th>\n",
              "      <th>traffic_volume_counted_after_2200_to_2300</th>\n",
              "      <th>traffic_volume_counted_after_2300_to_2400</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3R</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>43</td>\n",
              "      <td>78</td>\n",
              "      <td>116</td>\n",
              "      <td>144</td>\n",
              "      <td>132</td>\n",
              "      <td>115</td>\n",
              "      <td>150</td>\n",
              "      <td>184</td>\n",
              "      <td>169</td>\n",
              "      <td>136</td>\n",
              "      <td>129</td>\n",
              "      <td>89</td>\n",
              "      <td>122</td>\n",
              "      <td>124</td>\n",
              "      <td>110</td>\n",
              "      <td>69</td>\n",
              "      <td>73</td>\n",
              "      <td>28</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>26</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>1U</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>381</td>\n",
              "      <td>252</td>\n",
              "      <td>218</td>\n",
              "      <td>194</td>\n",
              "      <td>220</td>\n",
              "      <td>348</td>\n",
              "      <td>453</td>\n",
              "      <td>679</td>\n",
              "      <td>826</td>\n",
              "      <td>962</td>\n",
              "      <td>1158</td>\n",
              "      <td>1379</td>\n",
              "      <td>1376</td>\n",
              "      <td>1383</td>\n",
              "      <td>1453</td>\n",
              "      <td>1617</td>\n",
              "      <td>1669</td>\n",
              "      <td>1308</td>\n",
              "      <td>1068</td>\n",
              "      <td>928</td>\n",
              "      <td>885</td>\n",
              "      <td>798</td>\n",
              "      <td>650</td>\n",
              "      <td>613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1U</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>585</td>\n",
              "      <td>408</td>\n",
              "      <td>328</td>\n",
              "      <td>364</td>\n",
              "      <td>696</td>\n",
              "      <td>1929</td>\n",
              "      <td>4228</td>\n",
              "      <td>5634</td>\n",
              "      <td>5673</td>\n",
              "      <td>4636</td>\n",
              "      <td>3925</td>\n",
              "      <td>3827</td>\n",
              "      <td>4049</td>\n",
              "      <td>3954</td>\n",
              "      <td>4077</td>\n",
              "      <td>4244</td>\n",
              "      <td>4405</td>\n",
              "      <td>4609</td>\n",
              "      <td>4361</td>\n",
              "      <td>3272</td>\n",
              "      <td>2243</td>\n",
              "      <td>2050</td>\n",
              "      <td>1453</td>\n",
              "      <td>892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1U</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>105</td>\n",
              "      <td>73</td>\n",
              "      <td>68</td>\n",
              "      <td>66</td>\n",
              "      <td>77</td>\n",
              "      <td>113</td>\n",
              "      <td>254</td>\n",
              "      <td>367</td>\n",
              "      <td>487</td>\n",
              "      <td>668</td>\n",
              "      <td>870</td>\n",
              "      <td>996</td>\n",
              "      <td>1003</td>\n",
              "      <td>1000</td>\n",
              "      <td>1043</td>\n",
              "      <td>1011</td>\n",
              "      <td>959</td>\n",
              "      <td>851</td>\n",
              "      <td>708</td>\n",
              "      <td>559</td>\n",
              "      <td>457</td>\n",
              "      <td>297</td>\n",
              "      <td>207</td>\n",
              "      <td>110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>23</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>4R</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>17</td>\n",
              "      <td>52</td>\n",
              "      <td>64</td>\n",
              "      <td>68</td>\n",
              "      <td>82</td>\n",
              "      <td>96</td>\n",
              "      <td>99</td>\n",
              "      <td>87</td>\n",
              "      <td>87</td>\n",
              "      <td>83</td>\n",
              "      <td>61</td>\n",
              "      <td>55</td>\n",
              "      <td>35</td>\n",
              "      <td>29</td>\n",
              "      <td>21</td>\n",
              "      <td>23</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>25</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2U</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1168</td>\n",
              "      <td>781</td>\n",
              "      <td>738</td>\n",
              "      <td>425</td>\n",
              "      <td>279</td>\n",
              "      <td>395</td>\n",
              "      <td>715</td>\n",
              "      <td>1202</td>\n",
              "      <td>1486</td>\n",
              "      <td>1819</td>\n",
              "      <td>2193</td>\n",
              "      <td>2401</td>\n",
              "      <td>2691</td>\n",
              "      <td>2508</td>\n",
              "      <td>2700</td>\n",
              "      <td>2673</td>\n",
              "      <td>2746</td>\n",
              "      <td>2564</td>\n",
              "      <td>2257</td>\n",
              "      <td>2140</td>\n",
              "      <td>2060</td>\n",
              "      <td>2156</td>\n",
              "      <td>1873</td>\n",
              "      <td>1590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3U</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>34</td>\n",
              "      <td>43</td>\n",
              "      <td>27</td>\n",
              "      <td>48</td>\n",
              "      <td>88</td>\n",
              "      <td>269</td>\n",
              "      <td>334</td>\n",
              "      <td>476</td>\n",
              "      <td>444</td>\n",
              "      <td>355</td>\n",
              "      <td>375</td>\n",
              "      <td>434</td>\n",
              "      <td>492</td>\n",
              "      <td>499</td>\n",
              "      <td>539</td>\n",
              "      <td>542</td>\n",
              "      <td>571</td>\n",
              "      <td>559</td>\n",
              "      <td>395</td>\n",
              "      <td>351</td>\n",
              "      <td>262</td>\n",
              "      <td>217</td>\n",
              "      <td>153</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>27</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4U</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>17</td>\n",
              "      <td>47</td>\n",
              "      <td>95</td>\n",
              "      <td>158</td>\n",
              "      <td>151</td>\n",
              "      <td>151</td>\n",
              "      <td>141</td>\n",
              "      <td>184</td>\n",
              "      <td>193</td>\n",
              "      <td>219</td>\n",
              "      <td>217</td>\n",
              "      <td>238</td>\n",
              "      <td>278</td>\n",
              "      <td>250</td>\n",
              "      <td>154</td>\n",
              "      <td>130</td>\n",
              "      <td>84</td>\n",
              "      <td>56</td>\n",
              "      <td>21</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>26</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>1R</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>115</td>\n",
              "      <td>78</td>\n",
              "      <td>31</td>\n",
              "      <td>40</td>\n",
              "      <td>42</td>\n",
              "      <td>134</td>\n",
              "      <td>268</td>\n",
              "      <td>335</td>\n",
              "      <td>392</td>\n",
              "      <td>441</td>\n",
              "      <td>600</td>\n",
              "      <td>722</td>\n",
              "      <td>652</td>\n",
              "      <td>706</td>\n",
              "      <td>751</td>\n",
              "      <td>740</td>\n",
              "      <td>784</td>\n",
              "      <td>822</td>\n",
              "      <td>703</td>\n",
              "      <td>425</td>\n",
              "      <td>192</td>\n",
              "      <td>159</td>\n",
              "      <td>150</td>\n",
              "      <td>168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2U</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>189</td>\n",
              "      <td>100</td>\n",
              "      <td>115</td>\n",
              "      <td>108</td>\n",
              "      <td>219</td>\n",
              "      <td>527</td>\n",
              "      <td>1212</td>\n",
              "      <td>1596</td>\n",
              "      <td>1347</td>\n",
              "      <td>1115</td>\n",
              "      <td>1114</td>\n",
              "      <td>1126</td>\n",
              "      <td>1178</td>\n",
              "      <td>1193</td>\n",
              "      <td>1364</td>\n",
              "      <td>1662</td>\n",
              "      <td>1673</td>\n",
              "      <td>1519</td>\n",
              "      <td>1148</td>\n",
              "      <td>914</td>\n",
              "      <td>808</td>\n",
              "      <td>555</td>\n",
              "      <td>468</td>\n",
              "      <td>270</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   day_of_data  ...  traffic_volume_counted_after_2300_to_2400\n",
              "0            7  ...                                          6\n",
              "1           26  ...                                        613\n",
              "2           16  ...                                        892\n",
              "3           26  ...                                        110\n",
              "4           23  ...                                          7\n",
              "5           25  ...                                       1590\n",
              "6           10  ...                                         61\n",
              "7           27  ...                                         14\n",
              "8           26  ...                                        168\n",
              "9           12  ...                                        270\n",
              "\n",
              "[10 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YRXqk-BZ-Zu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "76b304d5-95ac-4da0-be40-aec813eef048"
      },
      "source": [
        "traffic_df.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7140391, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYP5L6inFKBx",
        "colab_type": "code",
        "outputId": "9a56e0b0-7016-4e9a-e3e9-4ecee9923bd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "one_hot_column = ['direction_of_travel', 'functional_classification','direction_of_travel','lane_of_travel','month_of_data','day_of_week','day_of_data']\n",
        "prefix = []\n",
        "for col in one_hot_column:\n",
        "  prefix.append(col.replace('_',''))\n",
        "data = pd.get_dummies(traffic_df,prefix=prefix, columns=one_hot_column)\n",
        "data = data[:30000]\n",
        "data[:5]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>traffic_volume_counted_after_0000_to_0100</th>\n",
              "      <th>traffic_volume_counted_after_0100_to_0200</th>\n",
              "      <th>traffic_volume_counted_after_0200_to_0300</th>\n",
              "      <th>traffic_volume_counted_after_0300_to_0400</th>\n",
              "      <th>traffic_volume_counted_after_0400_to_0500</th>\n",
              "      <th>traffic_volume_counted_after_0500_to_0600</th>\n",
              "      <th>traffic_volume_counted_after_0600_to_0700</th>\n",
              "      <th>traffic_volume_counted_after_0700_to_0800</th>\n",
              "      <th>traffic_volume_counted_after_0800_to_0900</th>\n",
              "      <th>traffic_volume_counted_after_0900_to_1000</th>\n",
              "      <th>traffic_volume_counted_after_1000_to_1100</th>\n",
              "      <th>traffic_volume_counted_after_1100_to_1200</th>\n",
              "      <th>traffic_volume_counted_after_1200_to_1300</th>\n",
              "      <th>traffic_volume_counted_after_1300_to_1400</th>\n",
              "      <th>traffic_volume_counted_after_1400_to_1500</th>\n",
              "      <th>traffic_volume_counted_after_1500_to_1600</th>\n",
              "      <th>traffic_volume_counted_after_1600_to_1700</th>\n",
              "      <th>traffic_volume_counted_after_1700_to_1800</th>\n",
              "      <th>traffic_volume_counted_after_1800_to_1900</th>\n",
              "      <th>traffic_volume_counted_after_1900_to_2000</th>\n",
              "      <th>traffic_volume_counted_after_2000_to_2100</th>\n",
              "      <th>traffic_volume_counted_after_2100_to_2200</th>\n",
              "      <th>traffic_volume_counted_after_2200_to_2300</th>\n",
              "      <th>traffic_volume_counted_after_2300_to_2400</th>\n",
              "      <th>directionoftravel_0</th>\n",
              "      <th>directionoftravel_1</th>\n",
              "      <th>directionoftravel_2</th>\n",
              "      <th>directionoftravel_3</th>\n",
              "      <th>directionoftravel_4</th>\n",
              "      <th>directionoftravel_5</th>\n",
              "      <th>directionoftravel_6</th>\n",
              "      <th>directionoftravel_7</th>\n",
              "      <th>directionoftravel_8</th>\n",
              "      <th>directionoftravel_9</th>\n",
              "      <th>functionalclassification_1R</th>\n",
              "      <th>functionalclassification_1U</th>\n",
              "      <th>functionalclassification_2U</th>\n",
              "      <th>functionalclassification_3R</th>\n",
              "      <th>functionalclassification_3U</th>\n",
              "      <th>functionalclassification_4R</th>\n",
              "      <th>...</th>\n",
              "      <th>monthofdata_11</th>\n",
              "      <th>monthofdata_12</th>\n",
              "      <th>dayofweek_1</th>\n",
              "      <th>dayofweek_2</th>\n",
              "      <th>dayofweek_3</th>\n",
              "      <th>dayofweek_4</th>\n",
              "      <th>dayofweek_5</th>\n",
              "      <th>dayofweek_6</th>\n",
              "      <th>dayofweek_7</th>\n",
              "      <th>dayofdata_1</th>\n",
              "      <th>dayofdata_2</th>\n",
              "      <th>dayofdata_3</th>\n",
              "      <th>dayofdata_4</th>\n",
              "      <th>dayofdata_5</th>\n",
              "      <th>dayofdata_6</th>\n",
              "      <th>dayofdata_7</th>\n",
              "      <th>dayofdata_8</th>\n",
              "      <th>dayofdata_9</th>\n",
              "      <th>dayofdata_10</th>\n",
              "      <th>dayofdata_11</th>\n",
              "      <th>dayofdata_12</th>\n",
              "      <th>dayofdata_13</th>\n",
              "      <th>dayofdata_14</th>\n",
              "      <th>dayofdata_15</th>\n",
              "      <th>dayofdata_16</th>\n",
              "      <th>dayofdata_17</th>\n",
              "      <th>dayofdata_18</th>\n",
              "      <th>dayofdata_19</th>\n",
              "      <th>dayofdata_20</th>\n",
              "      <th>dayofdata_21</th>\n",
              "      <th>dayofdata_22</th>\n",
              "      <th>dayofdata_23</th>\n",
              "      <th>dayofdata_24</th>\n",
              "      <th>dayofdata_25</th>\n",
              "      <th>dayofdata_26</th>\n",
              "      <th>dayofdata_27</th>\n",
              "      <th>dayofdata_28</th>\n",
              "      <th>dayofdata_29</th>\n",
              "      <th>dayofdata_30</th>\n",
              "      <th>dayofdata_31</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>43</td>\n",
              "      <td>78</td>\n",
              "      <td>116</td>\n",
              "      <td>144</td>\n",
              "      <td>132</td>\n",
              "      <td>115</td>\n",
              "      <td>150</td>\n",
              "      <td>184</td>\n",
              "      <td>169</td>\n",
              "      <td>136</td>\n",
              "      <td>129</td>\n",
              "      <td>89</td>\n",
              "      <td>122</td>\n",
              "      <td>124</td>\n",
              "      <td>110</td>\n",
              "      <td>69</td>\n",
              "      <td>73</td>\n",
              "      <td>28</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>381</td>\n",
              "      <td>252</td>\n",
              "      <td>218</td>\n",
              "      <td>194</td>\n",
              "      <td>220</td>\n",
              "      <td>348</td>\n",
              "      <td>453</td>\n",
              "      <td>679</td>\n",
              "      <td>826</td>\n",
              "      <td>962</td>\n",
              "      <td>1158</td>\n",
              "      <td>1379</td>\n",
              "      <td>1376</td>\n",
              "      <td>1383</td>\n",
              "      <td>1453</td>\n",
              "      <td>1617</td>\n",
              "      <td>1669</td>\n",
              "      <td>1308</td>\n",
              "      <td>1068</td>\n",
              "      <td>928</td>\n",
              "      <td>885</td>\n",
              "      <td>798</td>\n",
              "      <td>650</td>\n",
              "      <td>613</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>585</td>\n",
              "      <td>408</td>\n",
              "      <td>328</td>\n",
              "      <td>364</td>\n",
              "      <td>696</td>\n",
              "      <td>1929</td>\n",
              "      <td>4228</td>\n",
              "      <td>5634</td>\n",
              "      <td>5673</td>\n",
              "      <td>4636</td>\n",
              "      <td>3925</td>\n",
              "      <td>3827</td>\n",
              "      <td>4049</td>\n",
              "      <td>3954</td>\n",
              "      <td>4077</td>\n",
              "      <td>4244</td>\n",
              "      <td>4405</td>\n",
              "      <td>4609</td>\n",
              "      <td>4361</td>\n",
              "      <td>3272</td>\n",
              "      <td>2243</td>\n",
              "      <td>2050</td>\n",
              "      <td>1453</td>\n",
              "      <td>892</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>105</td>\n",
              "      <td>73</td>\n",
              "      <td>68</td>\n",
              "      <td>66</td>\n",
              "      <td>77</td>\n",
              "      <td>113</td>\n",
              "      <td>254</td>\n",
              "      <td>367</td>\n",
              "      <td>487</td>\n",
              "      <td>668</td>\n",
              "      <td>870</td>\n",
              "      <td>996</td>\n",
              "      <td>1003</td>\n",
              "      <td>1000</td>\n",
              "      <td>1043</td>\n",
              "      <td>1011</td>\n",
              "      <td>959</td>\n",
              "      <td>851</td>\n",
              "      <td>708</td>\n",
              "      <td>559</td>\n",
              "      <td>457</td>\n",
              "      <td>297</td>\n",
              "      <td>207</td>\n",
              "      <td>110</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>17</td>\n",
              "      <td>52</td>\n",
              "      <td>64</td>\n",
              "      <td>68</td>\n",
              "      <td>82</td>\n",
              "      <td>96</td>\n",
              "      <td>99</td>\n",
              "      <td>87</td>\n",
              "      <td>87</td>\n",
              "      <td>83</td>\n",
              "      <td>61</td>\n",
              "      <td>55</td>\n",
              "      <td>35</td>\n",
              "      <td>29</td>\n",
              "      <td>21</td>\n",
              "      <td>23</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 116 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   traffic_volume_counted_after_0000_to_0100  ...  dayofdata_31\n",
              "0                                          4  ...             0\n",
              "1                                        381  ...             0\n",
              "2                                        585  ...             0\n",
              "3                                        105  ...             0\n",
              "4                                          6  ...             0\n",
              "\n",
              "[5 rows x 116 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6ZNeODPagsB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "607083b8-0fd2-4a53-96a2-bb607532417f"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30000, 116)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5bUGBLVU53X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat_index = {} # Mapping of feature -> start index of feature in a record\n",
        "cat_values = {} # Mapping of feature -> list of categorical values the feature can take\n",
        "# build up the cat_index and cat_values dictionary\n",
        "one_hot_column = ['direction_of_travel', 'functional_classification','direction_of_travel','lane_of_travel','month_of_data','day_of_week','day_of_data']\n",
        "for i, header in enumerate(data.keys()):\n",
        "  if i > 23: # categorical header\n",
        "    feature, value = header.split('_')\n",
        "    if feature not in cat_index:\n",
        "      cat_index[feature] = i\n",
        "      cat_values[feature] = [value]\n",
        "    else:\n",
        "      cat_values[feature].append(value)\n",
        "def get_onehot(record, feature):\n",
        "  \"\"\"\n",
        "  Return the portion of `record` that is the one-hot encoding\n",
        "  of feature. For example, since the feature \"work\" is stored\n",
        "  in the indices [5:12] in each record, calling `get_range(record, \"work\")`\n",
        "  is equivalent to accessing `record[5:12]`.\n",
        "  Args:\n",
        "  - record: a numpy array representing one record, formatted\n",
        "  the same way as a row in `data.np`\n",
        "  - feature: a string, should be an element of `catcols`\n",
        "  \"\"\"\n",
        "  start_index = cat_index[feature]\n",
        "  stop_index = cat_index[feature] + len(cat_values[feature])\n",
        "  return record[start_index:stop_index]\n",
        "def get_categorical_value(onehot, feature):\n",
        "  \"\"\"\n",
        "  Return the categorical value name of a feature given\n",
        "  a one-hot vector representing the feature.\n",
        "  Args:\n",
        "  - onehot: a numpy array one-hot representation of the feature\n",
        "  - feature: a string, should be an element of `catcols`\n",
        "  Examples:\n",
        "  >>> get_categorical_value(np.array([0., 0., 0., 0., 0., 1., 0.]), \"work\")\n",
        "  'State-gov'\n",
        "  >>> get_categorical_value(np.array([0.1, 0., 1.1, 0.2, 0., 1., 0.]), \"work\")\n",
        "  'Private'\n",
        "  \"\"\"\n",
        "  # TODO\n",
        "  idx = np.argmax(onehot)\n",
        "  return cat_values[feature][idx]\n",
        "def get_feature(record, feature):\n",
        "  \"\"\"\n",
        "  Return the categorical feature value of a record\n",
        "  \"\"\"\n",
        "  onehot = get_onehot(record, feature)\n",
        "  return get_categorical_value(onehot, feature)\n",
        "def get_features(record):\n",
        "  return { f: get_feature(record, f) for f in catcols }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J0vvE8pYK2s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "26d34b57-d07f-4552-dccb-f176bc755164"
      },
      "source": [
        "get_categorical_value(np.array([0.1, 0., 1.1, 3.3, 0., 1., 0.,0,0,0,0,0,0,0,55,0,0,0]), \"dayofdata\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'15'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pNXZ7DVbVfx",
        "colab_type": "text"
      },
      "source": [
        "#DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrsFBjwBZB5O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "14f7c814-dc7a-4d67-cbf0-d973fe3e7e85"
      },
      "source": [
        "np.random.seed(50) # set the numpy seed for consistent split\n",
        "arr = np.arange(len(data))\n",
        "np.random.shuffle(arr)\n",
        "np_data=data.values\n",
        "shuffled_data=np_data\n",
        "total_data=len(np_data)\n",
        "train_data=shuffled_data[:int(total_data*0.7)].astype(np.float32)\n",
        "validation_data=shuffled_data[int(total_data*0.7):int(total_data*0.85)].astype(np.float32)\n",
        "test_data=shuffled_data[int(total_data*0.85):].astype(np.float32)\n",
        "print(\"Training dataset size: {}\".format(train_data.shape[0]))\n",
        "print(\"Validation dataset size: {}\".format(validation_data.shape[0]))\n",
        "print(\"Test dataset size: {}\".format(test_data.shape[0]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training dataset size: 21000\n",
            "Validation dataset size: 4500\n",
            "Test dataset size: 4500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZV9VclvxBkk",
        "colab_type": "text"
      },
      "source": [
        "#Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA5R6RKGxBCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TnxuIqfxa_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cuda = torch.device('cuda')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAN0lAyGyH0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model_name(name, batch_size, learning_rate, epoch, momentum):\n",
        "  \"\"\" Generate a name for the model consisting of all the hyperparameter values\n",
        "  Args:\n",
        "  config: Configuration object containing the hyperparameters\n",
        "  Returns:\n",
        "  path: A string with the hyperparameter name and value concatenated\n",
        "  \"\"\"\n",
        "  if momentum:\n",
        "    path = \"model_{0}_bs{1}_lr{2}_epoch{3}_momentum{4}\".format(name,\n",
        "            batch_size,\n",
        "            learning_rate,\n",
        "            epoch,momentum)\n",
        "  else:\n",
        "    path = \"model_{0}_bs{1}_lr{2}_epoch{3}\".format(name,\n",
        "            batch_size,\n",
        "            learning_rate,\n",
        "            epoch)\n",
        "  return path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMwy_yq5xdhP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AutoEncoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(AutoEncoder, self).__init__()\n",
        "    self.encoder = nn.Sequential(\n",
        "    nn.Linear(116, 100), # TODO\n",
        "    nn.BatchNorm1d(num_features=100),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(100, 80),\n",
        "    nn.ReLU(),\n",
        "    )\n",
        "    self.decoder = nn.Sequential(\n",
        "    nn.Linear(80, 100),# TODO\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(100, 116),# TODO\n",
        "    nn.ReLU()\n",
        "    )\n",
        "    self.sig = nn.Sigmoid()\n",
        "  def forward(self, x):\n",
        "    x = self.encoder(x)\n",
        "    x = self.decoder(x)\n",
        "    x[:,24:] = self.sig(x[:,24:])\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HrXn4gcqHPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_accuracy(model, data_loader):\n",
        "    \"\"\"Return the \"accuracy\" of the autoencoder model across a data set\n",
        "    \n",
        "    Args:\n",
        "       - model: the autoencoder model, an instance of nn.Module\n",
        "       - data_loader: an instance of torch.utils.data.DataLoader\n",
        "\n",
        "    Example (to illustrate how get_accuracy is intended to be called.\n",
        "             depending on your variable naming this code might not work\n",
        "             out of the box)\n",
        "\n",
        "        >>> model = AutoEncoder()\n",
        "        >>> vdl = torch.utils.data.DataLoader(data_valid, batch_size=256, shuffle=True)\n",
        "        >>> get_accuracy(model, vdl)\n",
        "    \"\"\"\n",
        "    total = 0\n",
        "    acc = 0\n",
        "    count = 0\n",
        "    for j in range(24):\n",
        "        for item in data_loader: # minibatches\n",
        "            inp = item.detach().numpy()\n",
        "            out = model(zero_out_feature(item.clone())).detach().numpy()\n",
        "            for i in range(out.shape[0]): # record in minibatch\n",
        "                acc += np.square(int(out[i][j]) - inp[i][j] )\n",
        "                count += 1\n",
        "    return np.sqrt(acc)/count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H8yQsG38pX2n",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_training_curve(path):\n",
        "    train_err = np.loadtxt(\"{}_train_acc.csv\".format(path))\n",
        "    val_err = np.loadtxt(\"{}_val_acc.csv\".format(path))\n",
        "    train_loss = np.loadtxt(\"{}_train_loss.csv\".format(path))\n",
        "    val_loss = np.loadtxt(\"{}_val_loss.csv\".format(path))\n",
        "    plt.title(\"Train vs Validation Accuracy\")\n",
        "    plt.plot(range(1,train_err.shape[0]+1), train_err, label=\"Train\")\n",
        "    plt.plot(range(1,val_err.shape[0]+1), val_err, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "    plt.title(\"Train vs Validation Loss\")\n",
        "    plt.plot(range(1,train_loss.shape[0]+1), train_loss, label=\"Train\")\n",
        "    plt.plot(range(1,val_loss.shape[0]+1), val_loss, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "def zero_out_feature(records):\n",
        "    \"\"\" Set the feature missing in records, by setting the appropriate\n",
        "    columns of records to 0\n",
        "    \"\"\"\n",
        "    col = random.randint(0, 23)\n",
        "    records[:, col:24] = 0\n",
        "    return records\n",
        "\n",
        "def zero_out_random_feature(records):\n",
        "    \"\"\" Set one random feature missing in records, by setting the \n",
        "    appropriate columns of records to 0\n",
        "    \"\"\"\n",
        "    return zero_out_feature(records)\n",
        "def validation_eval(model, valid_loader, criterion):\n",
        "    valid_error = 0\n",
        "    total_valid_loss = 0\n",
        "    for data_val in valid_loader:\n",
        "        recon=model(data_val)\n",
        "        loss = criterion(recon, data_val)\n",
        "        total_valid_loss += loss.item()\n",
        "    return total_valid_loss/len(valid_loader),get_accuracy(model, valid_loader)\n",
        "        \n",
        "def train(model, train_loader, valid_loader, num_epochs=5, learning_rate=1e-4, batch_size=1,betas=(0.9, 0.999)):\n",
        "    \"\"\" Training loop. You should update this.\"\"\"\n",
        "    torch.manual_seed(42)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,betas=betas)\n",
        "    train_err = []    \n",
        "    train_loss = []  \n",
        "    val_err = []  \n",
        "    val_loss = []\n",
        "    for epoch in range(num_epochs):\n",
        "        train_error = 0\n",
        "        total_train_loss = 0\n",
        "        train_idx = 0\n",
        "        for data in train_loader:\n",
        "            data_zero = zero_out_feature(data.clone()) # zero out one categorical feature\n",
        "            recon = model(data_zero)\n",
        "            loss = criterion(recon, data)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            total_train_loss += loss.item()\n",
        "            if train_idx%1000==0:\n",
        "                train_err.append(get_accuracy(model,  train_loader))\n",
        "                train_loss.append(total_train_loss/(train_idx+1))\n",
        "                valid_loss,valid_err = validation_eval(model, valid_loader,criterion)\n",
        "                val_loss.append(valid_loss)\n",
        "                val_err.append(valid_err)\n",
        "            train_idx+=1\n",
        "        train_loss.append(total_train_loss/len(train_loader))\n",
        "        valid_loss,_= validation_eval(model, valid_loader,criterion)\n",
        "        val_loss.append(valid_loss)\n",
        "        print((\"Epoch {}: Train loss: {} Train flow loss: {} |\"+               \n",
        "               \"Validation loss: {} Valid flow loss: {}\").format(\n",
        "            epoch + 1, train_loss[-1],train_err[-1],val_loss[-1],val_err[-1]))\n",
        "        model_path = \"Encoder_Decoder_Batchsize{}_lr{}_epoch{}_betas{}\".format(batch_size,learning_rate,epoch,betas)\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "    print('Finished Training')    \n",
        "    np.savetxt(\"{}_train_loss.csv\".format(model_path), np.array(train_loss))       \n",
        "    np.savetxt(\"{}_val_loss.csv\".format(model_path), np.array(val_loss))\n",
        "    return model_path\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aby3mMinRRI",
        "colab_type": "code",
        "outputId": "65057acb-da8f-426a-b302-ae3eadac11a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "source": [
        "Encoder=AutoEncoder()\n",
        "batch_size=32\n",
        "train_loader =torch.utils.data.DataLoader(train_data,batch_size=batch_size) \n",
        "valid_loader =torch.utils.data.DataLoader(validation_data,batch_size=batch_size) \n",
        "test_loader =torch.utils.data.DataLoader(test_data,batch_size=batch_size) \n",
        "path = train(Encoder, train_loader, valid_loader, num_epochs=30, learning_rate=1e-2, batch_size=batch_size)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1: Train loss: 69306.07981503282 Train flow loss: 1.2681110222220153 |Validation loss: 58525.716519835994 Valid flow loss: 2.7753524469239537\n",
            "Epoch 2: Train loss: 60997.15062844844 Train flow loss: 0.8089677564642701 |Validation loss: 48512.25687056738 Valid flow loss: 1.7382892540594226\n",
            "Epoch 3: Train loss: 50883.528160524875 Train flow loss: 0.7394963926787577 |Validation loss: 30749.360074523494 Valid flow loss: 1.5833720854040476\n",
            "Epoch 4: Train loss: 40494.286465393714 Train flow loss: 0.6398757666825677 |Validation loss: 28172.23193359375 Valid flow loss: 1.3622215159140114\n",
            "Epoch 5: Train loss: 38639.433544327316 Train flow loss: 0.6119368734979769 |Validation loss: 24366.435335632756 Valid flow loss: 1.3044476213957465\n",
            "Epoch 6: Train loss: 37482.649598747266 Train flow loss: 0.5986780478014666 |Validation loss: 26166.26058808455 Valid flow loss: 1.258365554018844\n",
            "Epoch 7: Train loss: 35533.15435633086 Train flow loss: 0.5930652197053082 |Validation loss: 24701.67039110982 Valid flow loss: 1.2522529604427317\n",
            "Epoch 8: Train loss: 36860.568956163195 Train flow loss: 0.5908083263476155 |Validation loss: 23174.357993267953 Valid flow loss: 1.2513532910010574\n",
            "Epoch 9: Train loss: 35271.84056911149 Train flow loss: 0.5852680725094682 |Validation loss: 23078.71743579621 Valid flow loss: 1.2303876226576023\n",
            "Epoch 10: Train loss: 36561.670687369195 Train flow loss: 0.5692683299885347 |Validation loss: 21137.564309411016 Valid flow loss: 1.2036913902147963\n",
            "Epoch 11: Train loss: 35204.874149038005 Train flow loss: 0.5711231871575362 |Validation loss: 20582.574106202905 Valid flow loss: 1.1955261472930878\n",
            "Epoch 12: Train loss: 34029.20741548349 Train flow loss: 0.5706326406470059 |Validation loss: 19325.338159006536 Valid flow loss: 1.2173120520352119\n",
            "Epoch 13: Train loss: 35519.31008423409 Train flow loss: 0.5673471277145343 |Validation loss: 22100.33900916999 Valid flow loss: 1.194813261821337\n",
            "Epoch 14: Train loss: 34194.758612181315 Train flow loss: 0.5735015854137325 |Validation loss: 18563.055251966976 Valid flow loss: 1.2089838449410861\n",
            "Epoch 15: Train loss: 34446.763910813235 Train flow loss: 0.5622126309212645 |Validation loss: 20494.2621654754 Valid flow loss: 1.1797504739616582\n",
            "Epoch 16: Train loss: 33072.23970781904 Train flow loss: 0.5579112532844965 |Validation loss: 18931.339535544106 Valid flow loss: 1.1643662919360824\n",
            "Epoch 17: Train loss: 34082.52308113644 Train flow loss: 0.558095863040573 |Validation loss: 21560.613246620123 Valid flow loss: 1.183926093457794\n",
            "Epoch 18: Train loss: 34603.64375460783 Train flow loss: 0.5674799233972905 |Validation loss: 22543.09375 Valid flow loss: 1.188079999286696\n",
            "Epoch 19: Train loss: 32814.26539126415 Train flow loss: 0.5660243650980104 |Validation loss: 21251.849706338653 Valid flow loss: 1.1776354163612408\n",
            "Epoch 20: Train loss: 32982.275147599175 Train flow loss: 0.5668332794178935 |Validation loss: 19792.912450479278 Valid flow loss: 1.185872429869484\n",
            "Epoch 21: Train loss: 33027.36437486622 Train flow loss: 0.5485229167606767 |Validation loss: 18752.07864964262 Valid flow loss: 1.1463804993979367\n",
            "Epoch 22: Train loss: 31795.414259447538 Train flow loss: 0.5578303180693939 |Validation loss: 20428.806767024045 Valid flow loss: 1.16333525906458\n",
            "Epoch 23: Train loss: 33321.90216724041 Train flow loss: 0.5607218583477738 |Validation loss: 19519.19610725565 Valid flow loss: 1.1524210099794747\n",
            "Epoch 24: Train loss: 32544.79865458821 Train flow loss: 0.5575990991895357 |Validation loss: 19463.69712883699 Valid flow loss: 1.1669419719264627\n",
            "Epoch 25: Train loss: 29804.1183773604 Train flow loss: 0.5466469676690315 |Validation loss: 19002.793008574357 Valid flow loss: 1.166057742325059\n",
            "Epoch 26: Train loss: 33634.40757976747 Train flow loss: 0.5518399517551081 |Validation loss: 20697.57270369293 Valid flow loss: 1.143009741105174\n",
            "Epoch 27: Train loss: 31950.951181536577 Train flow loss: 0.5389055442306024 |Validation loss: 18548.072265625 Valid flow loss: 1.158255239877212\n",
            "Epoch 28: Train loss: 32745.19749861765 Train flow loss: 0.5572052240691663 |Validation loss: 18562.52733855552 Valid flow loss: 1.1793127207457559\n",
            "Epoch 29: Train loss: 29393.30636452685 Train flow loss: 0.5273373615639562 |Validation loss: 21949.914197556514 Valid flow loss: 1.1311646661234365\n",
            "Epoch 30: Train loss: 31552.90991545377 Train flow loss: 0.5555763128491827 |Validation loss: 21191.80046265514 Valid flow loss: 1.1471477156477168\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q28643PnnY3Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}